# AI Metrics & Evaluatie

Wat je niet meet, kun je niet verbeteren – dat geldt ook voor AI.  
AI-projecten moeten worden gestuurd op impact, performance en betrouwbaarheid.  
Niet alleen output meten, maar ook kwaliteit en gebruik.

---

## 1. Waarom AI-metrics?

- Helpt teams scherp te houden: werkt het echt?
- Voorkomt dat AI een gimmick blijft
- Maakt voortgang zichtbaar voor stakeholders
- Ondersteunt prioritering en doorontwikkeling

---

## 2. Soorten metrics

| Categorie       | Voorbeelden                                             |
|----------------|----------------------------------------------------------|
| Gebruikersmetrics | # gebruikers, sessieduur, actieve prompts              |
| Kwaliteitsmetrics | Hallucinatiegraad, correcties door gebruiker, NPS       |
| Feedbackmetrics   | Thumbs up/down, suggesties, sentimentanalyse          |
| Performance       | Snelheid, uptime, foutmarges                          |
| Impact            | Tijdswinst, foutreductie, klanttevredenheid            |

---

## 3. Meetmomenten

| Moment          | Wat meten                                              |
|-----------------|--------------------------------------------------------|
| Tijdens MVP     | Use case validatie, eerste feedback                    |
| Na launch       | Uptime, gebruik, correctiepercentage                   |
| Maandelijks     | Trend in adoption, bottlenecks, sentiment              |
| Per kwartaal    | ROI-berekening, uitbreiding naar andere use cases      |

---

## 4. Metrics per use case type

| Type                | Specifieke KPI’s                                     |
|---------------------|------------------------------------------------------|
| Chatbot             | Resolutiegraad, klanttevredenheid, escalatie %       |
| Assistent (intern)  | Tijdswinst per rol, correctie %                       |
| Automatisering      | Aantal succesvolle runs, tijdsbesparing              |
| Inzichten            | Gebruik dashboards, actie op basis van output       |

---

## 5. Feedbackstructuur

- Ingebouwde feedbackopties (duimpje, suggestieveld)
- Frequentie: minimaal 1x per maand review van feedback
- Acties loggen op feedback (“verwerkt”, “genegeerd met reden”)
- Teamleden betrekken bij interpretatie

---

## 6. AI Scorecard Template

| Domein           | Score (1-5) | Toelichting                             |
|------------------|-------------|------------------------------------------|
| Adoption         |             |                                          |
| Kwaliteit output |             |                                          |
| Feedbackloops    |             |                                          |
| Uptime           |             |                                          |
| Business impact  |             |                                          |

Doel: alles ≥ 4 voor opschaling.

---

## 7. Valkuilen

- Alleen outputvolume meten (“we genereren 500 antwoorden per dag!”)
- Geen correlatie met business impact
- Feedback wordt niet gelogd of genegeerd
- Metrics ≠ purpose → vergeet het “waarom”

---

## 8. Conclusie

Zonder meten geen sturen.  
Zonder sturen geen leren.  
Zonder leren geen AI-succes.  
Maak AI-evaluatie onderdeel van je ritme, niet van je compliancecheck.

---
